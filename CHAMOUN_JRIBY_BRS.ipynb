{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "263dc36900ff48578ed27a0b28ae5bb9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_26dd4c5b2915403494d5f99a3314cf2c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "image/png": "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\n",
                  "text/plain": "<IPython.core.display.Image object>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "26dd4c5b2915403494d5f99a3314cf2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installs the necessary Python and system libraries\n",
        "try:\n",
        "    from easypip import easyimport, easyinstall, is_notebook\n",
        "except ModuleNotFoundError as e:\n",
        "    get_ipython().run_line_magic(\"pip\", \"install 'easypip>=1.2.0'\")\n",
        "    from easypip import easyimport, easyinstall, is_notebook\n",
        "\n",
        "easyinstall(\"swig\")\n",
        "easyinstall(\"bbrl>=0.2.2\")\n",
        "easyinstall(\"gymnasium\")\n",
        "easyinstall(\"mazemdp\")\n",
        "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
        "easyinstall(\"tensorboard\")\n",
        "easyinstall(\"box2d-kengz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qms6l1xhklUX",
        "outputId": "3d6deb18-fc85-4a7d-eef3-9d08f1a1e434"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[easypip] Installing bbrl_gymnasium>=0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WypvixuKaUtJ",
        "outputId": "f07898cd-9ef3-4c69-d1e7-b0814251fc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[easypip] Installing bbrl_gymnasium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matplotlib backend: module://matplotlib_inline.backend_inline\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "if is_notebook():\n",
        "    get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "easyimport(\"gymnasium\")\n",
        "easyimport(\"bbrl_gymnasium\")\n",
        "from bbrl_gymnasium.envs.maze_mdp import MazeMDPEnv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import bbrl_gymnasium\n",
        "\n",
        "bbrl_env = gym.make('MazeMDP-v0', kwargs={\"width\": 5, \"height\": 5, \"ratio\": 0.2})\n",
        "bbrl_env.reset()\n",
        "\n",
        "bbrl_env.init_draw(\"The maze\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569,
          "referenced_widgets": [
            "263dc36900ff48578ed27a0b28ae5bb9",
            "26dd4c5b2915403494d5f99a3314cf2c"
          ]
        },
        "id": "AclaCiwrkQZS",
        "outputId": "3582a8c2-b034-4fe5-fed8-b821968b5a4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.init_draw to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.init_draw` for environment variables or `env.get_wrapper_attr('init_draw')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "263dc36900ff48578ed27a0b28ae5bb9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_function(policy, env, horizon):\n",
        "    \"\"\"\n",
        "    Calculates the total reward accumulated by following the given policy in the environment until termination\n",
        "    or reaching the maximum number of steps.\n",
        "\n",
        "    Args:\n",
        "        policy (callable): The policy function that maps observations to actions.\n",
        "        env (gym.Env): The environment.\n",
        "        horizon (int): The maximum number of steps to take.\n",
        "\n",
        "    Returns:\n",
        "        float: The total accumulated reward.\n",
        "    \"\"\"\n",
        "    total_reward = 0\n",
        "    observation = env.reset()\n",
        "    for _ in range(horizon):\n",
        "        action = policy(observation)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    return total_reward\n",
        "\n",
        "\n",
        "def basic_random_search(env_name, step_size, num_directions, noise_std, max_iterations, horizon):\n",
        "    \"\"\"\n",
        "    Performs basic random search to optimize parameters for a given environment.\n",
        "\n",
        "    Args:\n",
        "        env_name (str): Name of the environment.\n",
        "        step_size (float): Step size for parameter updates.\n",
        "        num_directions (int): Number of directions sampled per iteration.\n",
        "        noise_std (float): Standard deviation of exploration noise.\n",
        "        max_iterations (int): Maximum number of iterations.\n",
        "        horizon (int): Maximum number of steps per rollout.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Optimal parameters found through random search.\n",
        "    \"\"\"\n",
        "    env = gym.make(env_name)\n",
        "    num_params = env.observation_space.shape[0]\n",
        "\n",
        "    theta = np.zeros(num_params)\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        # Sample directions:\n",
        "        ## Sample N directions (δ1, δ2, ..., δN) of the same size as the current parameters θj from the standard normal distribution.\n",
        "        directions = np.random.randn(num_directions, num_params)\n",
        "\n",
        "        # Collect rollouts and rewards:\n",
        "        for direction in directions:\n",
        "            # Construct two policies for each direction\n",
        "            ## (We clip the action to ensure it falls within the valid action space defined by env.action_space.low and env.action_space.high)\n",
        "            policy_plus = lambda obs: np.clip(theta + noise_std * direction, env.action_space.low, env.action_space.high) # πj,k,+(x) = πθj+νδk(x)\n",
        "            policy_minus = lambda obs: np.clip(theta - noise_std * direction, env.action_space.low, env.action_space.high) # πj,k,−(x) = πθj−νδk(x)\n",
        "\n",
        "            # Calculate rewards for each policy\n",
        "            reward_plus = objective_function(policy_plus, env, horizon)\n",
        "            reward_minus = objective_function(policy_minus, env, horizon)\n",
        "\n",
        "            # Update parameters:\n",
        "            update_step = (step_size / num_directions) * np.sum(reward_plus - reward_minus) * direction\n",
        "            theta += update_step\n",
        "\n",
        "    env.close()\n",
        "    return theta\n",
        "\n",
        "\n",
        "# Example:\n",
        "env_name = 'Pendulum-v1'   # Environment: Pendulum\n",
        "step_size = 0.05           # Step size for parameter updates\n",
        "num_directions = 20        # Number of directions sampled per iteration\n",
        "noise_std = 0.2            # Standard deviation of exploration noise\n",
        "max_iterations = 50        # Maximum number of iterations\n",
        "horizon = 150              # Horizon (number of time steps per rollout)\n",
        "\n",
        "# Run BRS\n",
        "optimal_params = basic_random_search(env_name, step_size, num_directions, noise_std, max_iterations, horizon)\n",
        "\n",
        "# Print the optimal parameters found\n",
        "print(\"Optimal Parameters:\", optimal_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww1QXa7esAoU",
        "outputId": "bd3ed4b8-663e-4163-c3e0-553370d12ce0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Parameters: [  3.5980421  -25.75099216  21.10023133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# OUR ATTEMPT USING BBRL #\n",
        "##########################\n",
        "\n",
        "from mazemdp.toolbox import egreedy, egreedy_loc\n",
        "\n",
        "def objective_function(mdp: MazeMDPEnv, policy, epsilon = 0.02):\n",
        "    \"\"\"\n",
        "    Calculates the total reward accumulated by following the given policy in the MazeMDPEnv environment until termination\n",
        "    or reaching the maximum number of steps, using an ε-greedy strategy for action selection.\n",
        "\n",
        "    Args:\n",
        "        mdp (MazeMDPEnv): The MazeMDPEnv environment.\n",
        "        policy (callable): The policy function that maps states to actions.\n",
        "        epsilon (float, optional): The epsilon value for ε-greedy action selection. Defaults to 0.02.\n",
        "\n",
        "    Returns:\n",
        "        float: The total accumulated reward.\n",
        "    \"\"\"\n",
        "    total_reward = 0\n",
        "    state, _ = mdp.reset(uniform = True)\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    while not (terminated or truncated):\n",
        "        action = egreedy(policy, state, epsilon)  # Using ε-greedy since step in BBRL takes as parameter the index of the action\n",
        "        observation, reward, terminated, truncated, _ = mdp.step(action)\n",
        "        total_reward += reward\n",
        "        state = observation\n",
        "    return total_reward\n",
        "\n",
        "\n",
        "def basic_random_search(mdp: MazeMDPEnv, step_size, num_directions, noise_std, max_iterations):\n",
        "    \"\"\"\n",
        "    Performs basic random search to optimize parameters for a given MazeMDPEnv environment.\n",
        "\n",
        "    Args:\n",
        "        mdp (MazeMDPEnv): The MazeMDPEnv environment.\n",
        "        step_size (float): Step size for parameter updates.\n",
        "        num_directions (int): Number of directions sampled per iteration.\n",
        "        noise_std (float): Standard deviation of exploration noise.\n",
        "        max_iterations (int): Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Optimal parameters found through random search.\n",
        "    \"\"\"\n",
        "    theta = np.zeros((mdp.nb_states, mdp.action_space.n))\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        # Sample directions:\n",
        "        ## Sample N directions (δ1, δ2, ..., δN) of the same size as the current parameters θj from the standard normal distribution.\n",
        "        directions = np.random.randn(num_directions, mdp.action_space.n)\n",
        "\n",
        "        # Collect rollouts and rewards:\n",
        "        for direction in directions:\n",
        "            # Construct two policies for each direction\n",
        "            policy_plus = theta + noise_std * direction   # πj,k,+(x) = πθj+νδk(x)\n",
        "            policy_minus = theta - noise_std * direction  # πj,k,−(x) = πθj−νδk(x)\n",
        "\n",
        "            # Calculate rewards for each policy\n",
        "            reward_plus = objective_function(mdp, policy_plus)\n",
        "            reward_minus = objective_function(mdp, policy_minus)\n",
        "\n",
        "            # Update parameters:\n",
        "            update_step = (step_size / num_directions) * np.sum(reward_plus - reward_minus) * direction\n",
        "            theta += update_step\n",
        "\n",
        "    return theta[-1]\n",
        "\n",
        "\n",
        "# Example:\n",
        "step_size = 0.05           # Step size for parameter updates\n",
        "num_directions = 20        # Number of directions sampled per iteration\n",
        "noise_std = 0.2            # Standard deviation of exploration noise\n",
        "max_iterations = 50        # Maximum number of iterations\n",
        "\n",
        "# Run BRS\n",
        "optimal_params = basic_random_search(bbrl_env, step_size, num_directions, noise_std, max_iterations)\n",
        "\n",
        "# Print the optimal parameters found\n",
        "print(\"Optimal Parameters:\", optimal_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_kgXKOua6pS",
        "outputId": "a28cb96f-29ff-4d15-bbb1-7e4299c29c85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.nb_states to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.nb_states` for environment variables or `env.get_wrapper_attr('nb_states')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Parameters: [-0.15956021  0.14859785  0.22963451 -0.16514555]\n"
          ]
        }
      ]
    }
  ]
}